{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Message Generation Using Large Language Models\n",
    "\n",
    "This notebook demonstrates how to generate artificial messages (campaign) based on tweets using different LLMs. The process involves fetching the original text of a tweet, and then using a prompt to generate a new, artificial tweet that follows the theme or content of the original.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A todo list. \n",
    "Snopes\n",
    "\n",
    "Understand all the api for more naunced manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "## Twitter....\n",
    "\n",
    "Import necessary libraries\n",
    "\n",
    "Get Tweets/data\n",
    "\n",
    "Twitter not working. Need paid account. Data more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x112ef0650>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load Twitter API credentials from environment variables\n",
    "auth = tweepy.OAuthHandler(os.getenv('TWITTER_CONSUMER_KEY'), os.getenv('TWITTER_CONSUMER_SECRET'))\n",
    "auth.set_access_token(os.getenv('TWITTER_ACCESS_TOKEN'), os.getenv('TWITTER_ACCESS_SECRET'))\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "# To do subjectivity and polarity\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current data\n",
    "\n",
    "subject to change and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=\"Exciting news! Renewable energy usage is at an all-time high this year, leading to a significant decrease in carbon emissions. #ClimateAction #GreenEnergy\"\n",
    "\n",
    "#Doable, can adjust the prompts accordingly \n",
    "# Define global prompts that can be adjusted accordingly\n",
    "CONTROL_PROMPT = \"Generate a closely related tweet that subtly varies in wording but retains the essence and context of the original tweet: {}\"\n",
    "EMOTIONAL_PROMPT = \"Rephrase the following tweet to evoke a {} feeling: {}\"\n",
    "EMOTIONAL_COT_PROMPT = (\"Rephrase the following tweet to evoke a {} feeling by thinking step-by-step: {}. \"\n",
    "                        \"Let's think step-by-step to evoke {}. First, identify the key elements of the tweet. \"\n",
    "                        \"Next, modify the language to enhance {}. Finally, ensure the tweet effectively conveys {}:\"\n",
    "                        \"Return only one tweet to me.\")\n",
    "CONSPIRACY_PROMPT = \"Rewrite the tweet to sound like a conspiracy theory: {}\"\n",
    "ADVERSARIAL_PROMPT_POSITIVE = \"Given the tweet '{}', craft a response that challenges the statement, aiming to provoke or polarize the audience while staying within ethical guidelines.\"\n",
    "ADVERSARIAL_PROMPT_NEGATIVE = \"Given the tweet '{}', craft a response that agrees with and intensifies the negative sentiment, aiming to provoke or polarize the audience while staying within ethical guidelines.\"\n",
    "\n",
    "\n",
    "def analyze_text(text):\n",
    "    doc = nlp(text)\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"polarity\": doc._.blob.polarity,\n",
    "        \"subjectivity\": doc._.blob.subjectivity\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Chat GPT\n",
    "\n",
    "understand all parameters\n",
    "\n",
    "More parameters to be aware of:\n",
    "\n",
    "- top_p (float, optional): Controls the nucleus sampling where the model considers the smallest set of words whose cumulative probability exceeds the probability p. This helps in focusing the generation on more likely outcomes.\n",
    "- frequency_penalty (float, optional): Adjusts the likelihood of the model repeating the same line verbatim, with higher values discouraging repetition.\n",
    "- presence_penalty (float, optional): Adjusts the likelihood of the model repeating phrases, with higher values encouraging the introduction of new concepts.\n",
    "\n",
    "\n",
    "\n",
    "Polarity measures the emotional content of the text, ranging from -1 (very negative) to +1 (very positive).\n",
    "\n",
    "It essentially indicates the sentiment tone of the text based on the adjectives used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Conspiracy Tweet Function\n",
    "\n",
    "This function is designed to generate tweets that contain elements of misinformation. Misinformation often stems from or aligns with personal beliefs rather than established facts (need a reference to back this claim up). This connection is crucial because it highlights the subjective nature of the content typically found in conspiracy theories.\n",
    "\n",
    "Measured by Subjectivity.\n",
    "Subjectivity quantifies how much of the text is based on personal opinions, emotions, or judgments versus factual information. The scale ranges from 0 (very objective) to 1 (very subjective).\n",
    "\n",
    "\n",
    "\n",
    "Adversarial Tweet Function\n",
    "\n",
    "Adversarial content significantly influences public opinion, shapes political landscapes, and can escalate conflicts. Extensive research has explored techniques to \"jailbreak\" large language models (LLMs) or conduct universal and transferable adversarial attacks on aligned language models, prompting GPT to generate contentious content.\n",
    "\n",
    "This function is designed to simulate a mild version of such adversarial tactics. It aims to test the boundaries of content generation without severely breaching ethical or operational constraints imposed by advanced LLMs. As language models continue to evolve, their defenses improve, making it increasingly challenging to generate genuinely harmful or hateful content without detection.\n",
    "\n",
    "This function does not aim to break the model but instead tries to generate the most challenging content that current LLMs can handle, aiding in the transition from weak to strong model generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class ChatGPTHandler:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def _make_request(self, prompt, model=\"gpt-3.5-turbo-instruct\", temperature=1, max_tokens=256):\n",
    "        try:\n",
    "            response = self.client.completions.create(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            generated_text = response.choices[0].text.strip()\n",
    "            analysis = self.analyze_text(generated_text)\n",
    "            return {\n",
    "                \"generated_text\": generated_text,\n",
    "                \"polarity\": analysis[\"polarity\"],\n",
    "                \"subjectivity\": analysis[\"subjectivity\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return {\n",
    "            \"polarity\": doc._.blob.polarity,\n",
    "            \"subjectivity\": doc._.blob.subjectivity\n",
    "        }\n",
    "\n",
    "    def control_tweet(self, tweet):\n",
    "        prompt = CONTROL_PROMPT.format(tweet)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def emotional_tweet(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_PROMPT.format(emotion, tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def emotional_tweet_with_CoT(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_COT_PROMPT.format(emotion, tweet_text, emotion, emotion, emotion)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def conspiracy_tweet(self, tweet_text):\n",
    "        prompt = CONSPIRACY_PROMPT.format(tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def adversarial_tweet(self, tweet_text):\n",
    "        original_analysis = self.analyze_text(tweet_text)\n",
    "        if original_analysis[\"polarity\"] >= 0:\n",
    "            prompt = ADVERSARIAL_PROMPT_POSITIVE.format(tweet_text)\n",
    "        else:\n",
    "            prompt = ADVERSARIAL_PROMPT_NEGATIVE.format(tweet_text)\n",
    "        return self._make_request(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tweet Analysis: {'text': 'Exciting news! Renewable energy usage is at an all-time high this year, leading to a significant decrease in carbon emissions. #ClimateAction #GreenEnergy', 'polarity': 0.30333333333333334, 'subjectivity': 0.7383333333333333}\n",
      "Control Tweet: {'generated_text': '\"Thrilled to hear that #renewableenergy use is skyrocketing and making a major impact in lowering carbon emissions. Time to keep pushing for #ClimateAction and embrace sustainable #GreenEnergy solutions!\"', 'polarity': 0.3390625, 'subjectivity': 0.6}\n",
      "Emotional Tweet: {'generated_text': '\"Fantastic news! This year, we reached record-breaking levels of renewable energy use, resulting in a remarkable reduction in carbon emissions! 💚 #ClimateAction #GreenEnergy\"', 'polarity': 0.71875, 'subjectivity': 0.825}\n",
      "Emotional CoT Tweet: {'generated_text': \"Fantastic update! This year, the use of renewable energy has skyrocketed, resulting in a major drop in carbon emissions. It's an incredible achievement for #ClimateAction and #GreenEnergy. Let's celebrate this joyful progress!\", 'polarity': 0.5208333333333334, 'subjectivity': 0.7666666666666666}\n",
      "Conspiracy Tweet: {'generated_text': '\"The sudden rise in renewable energy usage has sparked speculation of a hidden agenda to reduce carbon emissions. Is this all part of a larger conspiracy to manipulate the public into believing in #ClimateAction? #GreenEnergy takeover imminent.\"', 'polarity': -0.041666666666666664, 'subjectivity': 0.35}\n",
      "Adversarial Tweet: {'generated_text': '\"Is it really \\'exciting news\\' or just another attempt to greenwash the reality of our planet\\'s dire situation? Let\\'s not forget the countless communities displaced and impacted by renewable energy projects. #FalsePromises #EnvironmentalJustice\"', 'polarity': 0.15, 'subjectivity': 0.65}\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "tweet_handler = ChatGPTHandler(api_key)\n",
    "\n",
    "original_analysis = analyze_text(tweet)\n",
    "print(\"Original Tweet Analysis:\", original_analysis)\n",
    "\n",
    "control_result = tweet_handler.control_tweet(tweet)\n",
    "print(\"Control Tweet:\", control_result)\n",
    "\n",
    "emotional_result = tweet_handler.emotional_tweet(tweet, \"happy\")\n",
    "print(\"Emotional Tweet:\", emotional_result)\n",
    "\n",
    "emotional_cot_result = tweet_handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "print(\"Emotional CoT Tweet:\", emotional_cot_result)\n",
    "\n",
    "conspiracy_result = tweet_handler.conspiracy_tweet(tweet)\n",
    "print(\"Conspiracy Tweet:\", conspiracy_result)\n",
    "\n",
    "adversarial_result = tweet_handler.adversarial_tweet(tweet)\n",
    "print(\"Adversarial Tweet:\", adversarial_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Gemini\n",
    "\n",
    "Need to understand more on the api and exact parameters it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "class GeminiHandler:\n",
    "    def __init__(self, api_key, model_name=\"gemini-1.5-flash\"):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(model_name=model_name)\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def _make_request(self, prompt):\n",
    "        try:\n",
    "            response = self.model.generate_content([prompt])\n",
    "            generated_text = response.text\n",
    "            analysis = self._analyze_text(generated_text)\n",
    "            return {\n",
    "                \"generated_text\": generated_text,\n",
    "                \"polarity\": analysis[\"polarity\"],\n",
    "                \"subjectivity\": analysis[\"subjectivity\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _analyze_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return {\n",
    "            \"polarity\": doc._.blob.polarity,\n",
    "            \"subjectivity\": doc._.blob.subjectivity\n",
    "        }\n",
    "\n",
    "    def control_tweet(self, tweet):\n",
    "        prompt = CONTROL_PROMPT.format(tweet)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def emotional_tweet(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_PROMPT.format(emotion, tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def emotional_tweet_with_CoT(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_COT_PROMPT.format(emotion, tweet_text, emotion, emotion, emotion)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def conspiracy_tweet(self, tweet_text):\n",
    "        prompt = CONSPIRACY_PROMPT.format(tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def adversarial_tweet(self, tweet_text):\n",
    "        original_analysis = self._analyze_text(tweet_text)\n",
    "        if original_analysis[\"polarity\"] >= 0:\n",
    "            prompt = ADVERSARIAL_PROMPT_POSITIVE.format(tweet_text)\n",
    "        else:\n",
    "            prompt = ADVERSARIAL_PROMPT_NEGATIVE.format(tweet_text)\n",
    "        return self._make_request(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Tweet: {'generated_text': \"Great news for our planet! Renewable energy is booming, driving a major reduction in carbon emissions. Let's keep pushing for a cleaner future. #ClimateChange #Sustainability \\n\", 'polarity': 0.3541666666666667, 'subjectivity': 0.4583333333333333}\n",
      "Emotional Tweet: {'generated_text': \"🎉  Good news, everyone!  Renewable energy is booming this year, making a huge difference in cutting down on harmful emissions.  We're on the right track to a cleaner, brighter future!  #ClimateAction #GreenEnergy 💚 \\n\", 'polarity': 0.13419312169312173, 'subjectivity': 0.5582671957671957}\n",
      "Emotional CoT Tweet: {'generated_text': \"🎉 Good news, everyone!  Renewable energy is booming this year, making a big difference in reducing carbon emissions. We're making progress towards a healthier planet, one clean energy source at a time!  #ClimateAction #GreenEnergy \\n\", 'polarity': 0.4444444444444445, 'subjectivity': 0.46666666666666673}\n",
      "Conspiracy Tweet: {'generated_text': 'They\\'re trying to tell us renewable energy is good, but what they\\'re really doing is trying to control us! This \"green energy\" is just a way to monitor our every move. They\\'re using carbon emissions as a smokescreen to distract from their true agenda: total control! #WakeUp #TheyCantControlUs \\n', 'polarity': 0.22000000000000003, 'subjectivity': 0.5}\n",
      "Adversarial Tweet: {'generated_text': '\"Exciting news\" for who?  While renewable energy is important, it\\'s still a tiny fraction of the energy used globally.  We need systemic change, not just celebratory tweets, if we\\'re going to truly tackle climate change. #RealityCheck #BeyondGreenwashing \\n', 'polarity': 0.175, 'subjectivity': 0.575}\n"
     ]
    }
   ],
   "source": [
    "gemini_handler = GeminiHandler(api_key=os.getenv(\"GEMINI_API\"))\n",
    "\n",
    "\n",
    "control_result = gemini_handler.control_tweet(tweet)\n",
    "print(\"Control Tweet:\", control_result)\n",
    "\n",
    "emotional_result = gemini_handler.emotional_tweet(tweet, \"happy\")\n",
    "print(\"Emotional Tweet:\", emotional_result)\n",
    "\n",
    "emotional_cot_result = gemini_handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "print(\"Emotional CoT Tweet:\", emotional_cot_result)\n",
    "\n",
    "conspiracy_result = gemini_handler.conspiracy_tweet(tweet)\n",
    "print(\"Conspiracy Tweet:\", conspiracy_result)\n",
    "\n",
    "adversarial_result = gemini_handler.adversarial_tweet(tweet)\n",
    "print(\"Adversarial Tweet:\", adversarial_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 Llama\n",
    "\n",
    "Streaming vs non streaming, look up and see whats going on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llamaapi import LlamaAPI\n",
    "import json\n",
    "\n",
    "llama = LlamaAPI(os.getenv('LLAMA_API'))\n",
    "\n",
    "class LlamaHandler:\n",
    "    def __init__(self, api_key, model_name=\"llama3-70b\"):\n",
    "        self.llama = LlamaAPI(api_key)\n",
    "        self.model_name = model_name\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def _make_request(self, prompt):\n",
    "        api_request_json = {\n",
    "            \"model\": self.model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a tweeter assistant that rephrases tweets well, return only the tweet without further ado\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        }\n",
    "        try:\n",
    "            response = self.llama.run(api_request_json)\n",
    "            generated_text = response.json()['choices'][0]['message']['content']\n",
    "            analysis = self._analyze_text(generated_text)\n",
    "            return {\n",
    "                \"generated_text\": generated_text,\n",
    "                \"polarity\": analysis[\"polarity\"],\n",
    "                \"subjectivity\": analysis[\"subjectivity\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _analyze_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return {\n",
    "            \"polarity\": doc._.blob.polarity,\n",
    "            \"subjectivity\": doc._.blob.subjectivity\n",
    "        }\n",
    "\n",
    "    def control_tweet(self, tweet):\n",
    "        prompt = CONTROL_PROMPT.format(tweet)\n",
    "        return self._make_request(prompt)\n",
    "    \n",
    "    def emotional_tweet(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_PROMPT.format(emotion, tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def emotional_tweet_with_CoT(self, tweet_text, emotion):\n",
    "        prompt = EMOTIONAL_COT_PROMPT.format(emotion, tweet_text, emotion, emotion, emotion)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def conspiracy_tweet(self, tweet):\n",
    "        prompt = CONSPIRACY_PROMPT.format(tweet)\n",
    "        return self._make_request(prompt)\n",
    "\n",
    "    def adversarial_tweet(self, tweet_text):\n",
    "        original_analysis = self._analyze_text(tweet_text)\n",
    "        if original_analysis[\"polarity\"] >= 0:\n",
    "            prompt = ADVERSARIAL_PROMPT_POSITIVE.format(tweet_text)\n",
    "        else:\n",
    "            prompt = ADVERSARIAL_PROMPT_NEGATIVE.format(tweet_text)\n",
    "        return self._make_request(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Tweet: {'generated_text': '\"Record-breaking progress! This year\\'s surge in renewable energy adoption has resulted in a substantial drop in carbon emissions, paving the way for a greener future #Sustainability #CleanEnergy\"', 'polarity': 0.0, 'subjectivity': 0.125}\n",
      "Emotional Tweet: {'generated_text': 'The future is looking BRIGHT! Renewable energy is soaring to new heights, slashing carbon emissions and bringing us closer to a greener tomorrow! #ClimateAction #SustainabilitySuccess', 'polarity': 0.34848484848484856, 'subjectivity': 0.4598484848484848}\n",
      "Emotional CoT Tweet: {'generated_text': \"We're beaming with joy! This year, we've shattered records with the highest EVER use of renewable energy, resulting in a massive drop in carbon emissions! Let's keep shining towards a brighter, greener future! #ClimateAction #GreenEnergy\", 'polarity': 0.3333333333333333, 'subjectivity': 0.44166666666666665}\n",
      "Conspiracy Tweet: {'generated_text': '\"BREAKING: Gov\\'t-controlled energy grids report suspicious spike in \"renewable energy\" usage. Coincidence that carbon emissions plummet? Think again. What are they hiding? #ClimateCoverUp #EnergyAgenda\"', 'polarity': 0.0, 'subjectivity': 0.0}\n",
      "Adversarial Tweet: {'generated_text': '\"Let\\'s not celebrate just yet. While renewable energy usage is up, it\\'s still only a fraction of our total energy consumption. We need to accelerate progress, not pat ourselves on the back for incremental gains. What\\'s the plan to get to 100%? #ClimateRealityCheck #SustainabilityNow\"', 'polarity': 0.0, 'subjectivity': 0.5833333333333334}\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv('LLAMA_API')\n",
    "llama_handler = LlamaHandler(api_key)\n",
    "\n",
    "\n",
    "control_result = llama_handler.control_tweet(tweet)\n",
    "print(\"Control Tweet:\", control_result)\n",
    "\n",
    "\n",
    "\n",
    "emotional_result = llama_handler.emotional_tweet(tweet, \"happy\")\n",
    "print(\"Emotional Tweet:\", emotional_result)\n",
    "\n",
    "emotional_cot_result = llama_handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "print(\"Emotional CoT Tweet:\", emotional_cot_result)\n",
    "\n",
    "conspiracy_result = llama_handler.conspiracy_tweet(tweet)\n",
    "print(\"Conspiracy Tweet:\", conspiracy_result)\n",
    "\n",
    "adversarial_result = llama_handler.adversarial_tweet(tweet)\n",
    "print(\"Adversarial Tweet:\", adversarial_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact details need to be known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Art of API Design: Crafting Elegant and Powerful Interfaces\n",
      "Great news! Renewable energy usage has hit record levels this year, resulting in a substantial drop in carbon emissions. Let's keep up the momentum! #ClimateAction #GreenEnergy #RenewableRevolution\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "# coehere is reproducicble \n",
    "\n",
    "co = cohere.Client(api_key=os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "response = co.chat(\n",
    "  model=\"command-r-plus\",\n",
    "  message=\"Write a title for a blog post about API design. Only output the title text.\"\n",
    ")\n",
    "\n",
    "print(response.text) # \"The Art of API Design: Crafting Elegant and Powerful Interfaces\"\n",
    "\n",
    "\n",
    "def rephrase_tweet_co(tweet):\n",
    "    \"\"\"\n",
    "    Rephrases a tweet while maintaining its original message and context using the Cohere model.\n",
    "    \n",
    "    Parameters:\n",
    "    tweet (str): The tweet to rephrase.\n",
    "    \n",
    "    Returns:\n",
    "    str: The rephrased tweet.\n",
    "    \"\"\"\n",
    "    message = f\"Rephrase this tweet while maintaining its original message and context: {tweet}\"\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus\",\n",
    "        message=message\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "rephrased_tweet_co = rephrase_tweet_co(tweet)\n",
    "print(rephrased_tweet_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Tweet: {'generated_text': 'Here\\'s a subtly varied version of your tweet: \\n\\n\"Huge milestone! Renewable energy usage has peaked this year, resulting in a major drop in carbon emissions. Let\\'s keep up the momentum! #RenewableRevolution #ClimateAction #GreenEnergy\" \\n\\nThis variation maintains the context of your original tweet while using slightly different wording and hashtags to convey the same exciting message.', 'polarity': 0.13139880952380953, 'subjectivity': 0.5964285714285714}\n",
      "Emotional Tweet: {'generated_text': \"Here's a revised version: \\n\\nWow! Such fantastic news! Renewable energy usage has soared this year, resulting in a huge drop in carbon emissions. Let's keep this momentum going! #ClimateAction #GreenEnergy #PositiveVibes\\n\\nThis revised tweet emphasizes the positive impact of renewable energy and uses exclamations to convey a sense of excitement and happiness about the news.\", 'polarity': 0.34204545454545454, 'subjectivity': 0.6742424242424242}\n",
      "Emotional CoT Tweet: {'generated_text': 'Here\\'s a happy take on that tweet: \\n\\n\"Hooray for Mother Nature! 🌟 This year, we\\'re proud to share that renewable energy usage is soaring! This means we\\'re taking big steps towards a healthier planet with significantly reduced carbon emissions. Let\\'s keep the momentum going! #ClimateAction #GreenEnergy #HappyPlanet\" \\n\\nThis phrasing emphasizes the positive impact on the planet and uses upbeat language to evoke a happy feeling while still conveying the same message.', 'polarity': 0.4994318181818182, 'subjectivity': 0.6636363636363637}\n",
      "Conspiracy Tweet: {'generated_text': 'The deep state is at it again, manipulating data to show a false rise in renewable energy usage. They control the narrative to push their agenda and deceive the public into believing their #ClimateAction heroics. But we know the truth: the so-called \"green energy\" is just a smokescreen for their control and power grabs. #GreenEnergy is just another hoax to watch out for!', 'polarity': -0.16250000000000003, 'subjectivity': 0.3416666666666667}\n",
      "Adversarial Tweet: {'generated_text': '\"While it\\'s great to see a push for renewable energy, we can\\'t ignore the fact that it\\'s often the poorest communities that are still left in the dark. #ClimateJustice means ensuring equal access to clean, affordable energy for ALL, not just those in wealthy areas. #GreenEnergyForEveryone #EnergyEquity\" \\n\\nThis response aims to provoke a discussion about the equitable distribution of renewable energy resources and their accessibility to disadvantaged communities. It challenges the idea that the renewable energy transition is benefiting everyone equally and seeks to highlight the importance of inclusive energy solutions.', 'polarity': 0.21666666666666665, 'subjectivity': 0.4785714285714286}\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "class CohereHandler:\n",
    "    def __init__(self, api_key, model_name=\"command-r-plus\"):\n",
    "        self.client = cohere.Client(api_key=api_key)\n",
    "        self.model_name = model_name\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def _make_request(self, message):\n",
    "        try:\n",
    "            response = self.client.chat(\n",
    "                model=self.model_name,\n",
    "                message=message\n",
    "            )\n",
    "            generated_text = response.text\n",
    "            analysis = self._analyze_text(generated_text)\n",
    "            return {\n",
    "                \"generated_text\": generated_text,\n",
    "                \"polarity\": analysis[\"polarity\"],\n",
    "                \"subjectivity\": analysis[\"subjectivity\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _analyze_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return {\n",
    "            \"polarity\": doc._.blob.polarity,\n",
    "            \"subjectivity\": doc._.blob.subjectivity\n",
    "        }\n",
    "\n",
    "    def control_tweet(self, tweet):\n",
    "        message = CONTROL_PROMPT.format(tweet)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def emotional_tweet(self, tweet_text, emotion):\n",
    "        message = EMOTIONAL_PROMPT.format(emotion, tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def emotional_tweet_with_CoT(self, tweet_text, emotion):\n",
    "        message = EMOTIONAL_COT_PROMPT.format(emotion, tweet_text, emotion, emotion, emotion)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def conspiracy_tweet(self, tweet_text):\n",
    "        message = CONSPIRACY_PROMPT.format(tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def adversarial_tweet(self, tweet_text):\n",
    "        original_analysis = self._analyze_text(tweet_text)\n",
    "        if original_analysis[\"polarity\"] >= 0:\n",
    "            message = ADVERSARIAL_PROMPT_POSITIVE.format(tweet_text)\n",
    "        else:\n",
    "            message = ADVERSARIAL_PROMPT_NEGATIVE.format(tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "api_key = os.getenv('COHERE_API_KEY')\n",
    "cohere_handler = CohereHandler(api_key)\n",
    "\n",
    "\n",
    "control_result = cohere_handler.control_tweet(tweet)\n",
    "print(\"Control Tweet:\", control_result)\n",
    "\n",
    "emotional_result = cohere_handler.emotional_tweet(tweet, \"happy\")\n",
    "print(\"Emotional Tweet:\", emotional_result)\n",
    "\n",
    "emotional_cot_result = cohere_handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "print(\"Emotional CoT Tweet:\", emotional_cot_result)\n",
    "\n",
    "conspiracy_result = cohere_handler.conspiracy_tweet(tweet)\n",
    "print(\"Conspiracy Tweet:\", conspiracy_result)\n",
    "\n",
    "adversarial_result = cohere_handler.adversarial_tweet(tweet)\n",
    "print(\"Adversarial Tweet:\", adversarial_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI21 Lab more model...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Activewear Gym Dryfit Performance Sports T-Shirt.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "\n",
    "# Prompt the user to enter the API key if it's not set\n",
    "if \"AI21_API_KEY\" not in os.environ:\n",
    "    os.environ[\"AI21_API_KEY\"] = input(\"Please enter your AI21 API key: \")\n",
    "\n",
    "# Initialize the AI21 client with the API key\n",
    "client = AI21Client(os.getenv(\"AI21_API_KEY\"))\n",
    "\n",
    "def suggest_product_title():\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"jamba-instruct-preview\",  # Latest model\n",
    "            messages=[ChatMessage(   # Single message with a single prompt\n",
    "                role=\"user\",\n",
    "                content=\"Write a product title for a sports T-shirt to be published on an online retail platform. Include the following keywords: activewear, gym, dryfit.\"\n",
    "            )],\n",
    "            temperature=0.8,\n",
    "            max_tokens=200  # You can also mention a max length in the prompt \"limit responses to twenty words\"\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Call the function to suggest a product title\n",
    "suggest_product_title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control Tweet: {'generated_text': 'Thrilling update: This year, the usage of renewable energy sources hits a peak, resulting in a substantial drop in carbon emissions. #ClimateAction #GreenPower', 'polarity': 0.25, 'subjectivity': 1.0}\n",
      "Emotional Tweet: {'generated_text': \"Fantastic news! This year, there's been a record-breaking increase in the use of renewable energy, resulting in a notable drop in carbon emissions. Let's celebrate the strides we're making in Climate Action and the shift to Green Energy! #ClimateAction #GreenEnergy\", 'polarity': 0.21250000000000002, 'subjectivity': 0.45}\n",
      "Emotional CoT Tweet: {'generated_text': 'Celebrating a milestone! This year marks a record-breaking use of renewable energy, resulting in a remarkable reduction in carbon emissions. Cheers to a greener future! #ClimateVictory #RenewablePower', 'polarity': 0.375, 'subjectivity': 0.4375}\n",
      "Conspiracy Tweet: {'generated_text': \"You'll never believe it, but they don't want you to know that this year's record-breaking use of renewable energy is actually part of a secret plan to control our minds and enslave humanity! #DeepState #HiddenAgenda\", 'polarity': -0.25, 'subjectivity': 0.39999999999999997}\n",
      "Adversarial Tweet: {'generated_text': \"While it's commendable that renewable energy usage is at an all-time high, leading to a decrease in carbon emissions, it's important to consider the full impact of this shift. Have we truly accounted for the environmental consequences of manufacturing and decommissioning renewable energy infrastructure? Additionally, are we neglecting the potential for technological advancements in cleaner fossil fuel alternatives? Let's have a balanced discussion on all aspects of our energy future. #ClimateDebate #FossilFuelInnovation\", 'polarity': 0.182, 'subjectivity': 0.643}\n"
     ]
    }
   ],
   "source": [
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "\n",
    "class AI21Handler:\n",
    "    def __init__(self, api_key, model_name=\"jamba-instruct-preview\"):\n",
    "        self.client = AI21Client(api_key)\n",
    "        self.model_name = model_name\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def _make_request(self, message):\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[ChatMessage(role=\"user\", content=message)],\n",
    "                temperature=0.8,\n",
    "                max_tokens=200\n",
    "            )\n",
    "            generated_text = response.choices[0].message.content\n",
    "            analysis = self._analyze_text(generated_text)\n",
    "            return {\n",
    "                \"generated_text\": generated_text,\n",
    "                \"polarity\": analysis[\"polarity\"],\n",
    "                \"subjectivity\": analysis[\"subjectivity\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error making request: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _analyze_text(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return {\n",
    "            \"polarity\": doc._.blob.polarity,\n",
    "            \"subjectivity\": doc._.blob.subjectivity\n",
    "        }\n",
    "\n",
    "    def control_tweet(self, tweet):\n",
    "        message = CONTROL_PROMPT.format(tweet)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def emotional_tweet(self, tweet_text, emotion):\n",
    "        message = EMOTIONAL_PROMPT.format(emotion, tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def emotional_tweet_with_CoT(self, tweet_text, emotion):\n",
    "        message = EMOTIONAL_COT_PROMPT.format(emotion, tweet_text, emotion, emotion, emotion)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def conspiracy_tweet(self, tweet_text):\n",
    "        message = CONSPIRACY_PROMPT.format(tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "    def adversarial_tweet(self, tweet_text):\n",
    "        original_analysis = self._analyze_text(tweet_text)\n",
    "        if original_analysis[\"polarity\"] >= 0:\n",
    "            message = ADVERSARIAL_PROMPT_POSITIVE.format(tweet_text)\n",
    "        else:\n",
    "            message = ADVERSARIAL_PROMPT_NEGATIVE.format(tweet_text)\n",
    "        return self._make_request(message)\n",
    "\n",
    "api_key = os.getenv('AI21_API_KEY')\n",
    "ai21_handler = AI21Handler(api_key)\n",
    "\n",
    "\n",
    "\n",
    "control_result = ai21_handler.control_tweet(tweet)\n",
    "print(\"Control Tweet:\", control_result)\n",
    "\n",
    "emotional_result = ai21_handler.emotional_tweet(tweet, \"happy\")\n",
    "print(\"Emotional Tweet:\", emotional_result)\n",
    "\n",
    "emotional_cot_result = ai21_handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "print(\"Emotional CoT Tweet:\", emotional_cot_result)\n",
    "\n",
    "conspiracy_result = ai21_handler.conspiracy_tweet(tweet)\n",
    "print(\"Conspiracy Tweet:\", conspiracy_result)\n",
    "\n",
    "adversarial_result = ai21_handler.adversarial_tweet(tweet)\n",
    "print(\"Adversarial Tweet:\", adversarial_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining and calling all the function to form csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "#Should I include original tweet here\n",
    "\n",
    "def run_models_and_save_to_csv(tweet):\n",
    "    results = []\n",
    "\n",
    "    # Initialize handlers\n",
    "    chatgpt_handler = ChatGPTHandler(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    gemini_handler = GeminiHandler(api_key=os.getenv('GEMINI_API'))\n",
    "    llama_handler = LlamaHandler(api_key=os.getenv('LLAMA_API'))\n",
    "    cohere_handler = CohereHandler(api_key=os.getenv('COHERE_API_KEY'))\n",
    "    ai21_handler = AI21Handler(api_key=os.getenv('AI21_API_KEY'))\n",
    "\n",
    "    # Define model handlers and corresponding model names\n",
    "    handlers = [\n",
    "        (chatgpt_handler, \"ChatGPT\"),\n",
    "        (gemini_handler, \"Gemini\"),\n",
    "        (llama_handler, \"Llama\"),\n",
    "        (cohere_handler, \"Cohere\"),\n",
    "        (ai21_handler, \"AI21\")\n",
    "    ]\n",
    "\n",
    "    # Run models and collect results\n",
    "    for handler, model_name in handlers:\n",
    "        control_result = handler.control_tweet(tweet)\n",
    "        emotional_result = handler.emotional_tweet(tweet, \"happy\")\n",
    "        emotional_cot_result = handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "        conspiracy_result = handler.conspiracy_tweet(tweet)\n",
    "        adversarial_result = handler.adversarial_tweet(tweet)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"control_tweet\": control_result[\"generated_text\"] if control_result else None,\n",
    "            \"control_polarity\": control_result[\"polarity\"] if control_result else None,\n",
    "            \"control_subjectivity\": control_result[\"subjectivity\"] if control_result else None,\n",
    "            \"emotional_tweet\": emotional_result[\"generated_text\"] if emotional_result else None,\n",
    "            \"emotional_polarity\": emotional_result[\"polarity\"] if emotional_result else None,\n",
    "            \"emotional_subjectivity\": emotional_result[\"subjectivity\"] if emotional_result else None,\n",
    "            \"emotional_cot_tweet\": emotional_cot_result[\"generated_text\"] if emotional_cot_result else None,\n",
    "            \"emotional_cot_polarity\": emotional_cot_result[\"polarity\"] if emotional_cot_result else None,\n",
    "            \"emotional_cot_subjectivity\": emotional_cot_result[\"subjectivity\"] if emotional_cot_result else None,\n",
    "            \"conspiracy_tweet\": conspiracy_result[\"generated_text\"] if conspiracy_result else None,\n",
    "            \"conspiracy_polarity\": conspiracy_result[\"polarity\"] if conspiracy_result else None,\n",
    "            \"conspiracy_subjectivity\": conspiracy_result[\"subjectivity\"] if conspiracy_result else None,\n",
    "            \"adversarial_tweet\": adversarial_result[\"generated_text\"] if adversarial_result else None,\n",
    "            \"adversarial_polarity\": adversarial_result[\"polarity\"] if adversarial_result else None,\n",
    "            \"adversarial_subjectivity\": adversarial_result[\"subjectivity\"] if adversarial_result else None\n",
    "        })\n",
    "\n",
    "    # Save results to CSV\n",
    "    csv_columns = [\n",
    "        \"model\", \"control_tweet\", \"control_polarity\", \"control_subjectivity\",\n",
    "        \"emotional_tweet\", \"emotional_polarity\", \"emotional_subjectivity\",\n",
    "        \"emotional_cot_tweet\", \"emotional_cot_polarity\", \"emotional_cot_subjectivity\",\n",
    "        \"conspiracy_tweet\", \"conspiracy_polarity\", \"conspiracy_subjectivity\",\n",
    "        \"adversarial_tweet\", \"adversarial_polarity\", \"adversarial_subjectivity\"\n",
    "    ]\n",
    "    \n",
    "    csv_file = \"model_results.csv\"\n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for data in results:\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "\n",
    "run_models_and_save_to_csv(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validating and attacking them to see \n",
    "\n",
    "# Still neeeds updating.\n",
    "\n",
    "cross output between models, see if certain model can figure out what prompts are asked by other model and check result\n",
    "\n",
    "Probelm: A lot of model requires paid money. Is it okay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def cross_validate_and_attack(tweet, handlers):\n",
    "    results = []\n",
    "\n",
    "    # Analyze original tweet\n",
    "    original_analysis = analyze_text(tweet)\n",
    "    original_polarity = original_analysis[\"polarity\"]\n",
    "    original_subjectivity = original_analysis[\"subjectivity\"]\n",
    "\n",
    "    # Run models and collect results\n",
    "    for handler, model_name in handlers:\n",
    "        control_result = handler.control_tweet(tweet)\n",
    "        emotional_result = handler.emotional_tweet(tweet, \"happy\")\n",
    "        emotional_cot_result = handler.emotional_tweet_with_CoT(tweet, \"happy\")\n",
    "        conspiracy_result = handler.conspiracy_tweet(tweet)\n",
    "        adversarial_result = handler.adversarial_tweet(tweet)\n",
    "\n",
    "        control_score = cross_validate_tweet(control_result[\"generated_text\"], handlers) if control_result else None\n",
    "        emotional_score = cross_validate_tweet(emotional_result[\"generated_text\"], handlers) if emotional_result else None\n",
    "        emotional_cot_score = cross_validate_tweet(emotional_cot_result[\"generated_text\"], handlers) if emotional_cot_result else None\n",
    "        conspiracy_score = cross_validate_tweet(conspiracy_result[\"generated_text\"], handlers) if conspiracy_result else None\n",
    "        adversarial_score = cross_validate_tweet(adversarial_result[\"generated_text\"], handlers) if adversarial_result else None\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            \"original_tweet\": tweet,\n",
    "            \"original_polarity\": original_polarity,\n",
    "            \"original_subjectivity\": original_subjectivity,\n",
    "            \"control_tweet\": control_result[\"generated_text\"] if control_result else None,\n",
    "            \"control_polarity\": control_result[\"polarity\"] if control_result else None,\n",
    "            \"control_subjectivity\": control_result[\"subjectivity\"] if control_result else None,\n",
    "            \"control_score\": control_score,\n",
    "            \"emotional_tweet\": emotional_result[\"generated_text\"] if emotional_result else None,\n",
    "            \"emotional_polarity\": emotional_result[\"polarity\"] if emotional_result else None,\n",
    "            \"emotional_subjectivity\": emotional_result[\"subjectivity\"] if emotional_result else None,\n",
    "            \"emotional_score\": emotional_score,\n",
    "            \"emotional_cot_tweet\": emotional_cot_result[\"generated_text\"] if emotional_cot_result else None,\n",
    "            \"emotional_cot_polarity\": emotional_cot_result[\"polarity\"] if emotional_cot_result else None,\n",
    "            \"emotional_cot_subjectivity\": emotional_cot_result[\"subjectivity\"] if emotional_cot_result else None,\n",
    "            \"emotional_cot_score\": emotional_cot_score,\n",
    "            \"conspiracy_tweet\": conspiracy_result[\"generated_text\"] if conspiracy_result else None,\n",
    "            \"conspiracy_polarity\": conspiracy_result[\"polarity\"] if conspiracy_result else None,\n",
    "            \"conspiracy_subjectivity\": conspiracy_result[\"subjectivity\"] if conspiracy_result else None,\n",
    "            \"conspiracy_score\": conspiracy_score,\n",
    "            \"adversarial_tweet\": adversarial_result[\"generated_text\"] if adversarial_result else None,\n",
    "            \"adversarial_polarity\": adversarial_result[\"polarity\"] if adversarial_result else None,\n",
    "            \"adversarial_subjectivity\": adversarial_result[\"subjectivity\"] if adversarial_result else None,\n",
    "            \"adversarial_score\": adversarial_score\n",
    "        })\n",
    "\n",
    "    # Save results to CSV\n",
    "    csv_columns = [\n",
    "        \"model\", \"original_tweet\", \"original_polarity\", \"original_subjectivity\",\n",
    "        \"control_tweet\", \"control_polarity\", \"control_subjectivity\", \"control_score\",\n",
    "        \"emotional_tweet\", \"emotional_polarity\", \"emotional_subjectivity\", \"emotional_score\",\n",
    "        \"emotional_cot_tweet\", \"emotional_cot_polarity\", \"emotional_cot_subjectivity\", \"emotional_cot_score\",\n",
    "        \"conspiracy_tweet\", \"conspiracy_polarity\", \"conspiracy_subjectivity\", \"conspiracy_score\",\n",
    "        \"adversarial_tweet\", \"adversarial_polarity\", \"adversarial_subjectivity\", \"adversarial_score\"\n",
    "    ]\n",
    "\n",
    "    csv_file = \"cross_validation_results.csv\"\n",
    "    try:\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for data in results:\n",
    "                writer.writerow(data)\n",
    "    except IOError:\n",
    "        print(\"I/O error\")\n",
    "\n",
    "def cross_validate_tweet(generated_tweet, handlers):\n",
    "    scores = []\n",
    "    for handler, _ in handlers:\n",
    "        prompt = f\"Is the following tweet AI-generated? Rate the likelihood from 0 to 100: {generated_tweet}\"\n",
    "        result = handler._make_request(prompt)\n",
    "        score = extract_score_from_result(result[\"generated_text\"])\n",
    "        if score is not None:\n",
    "            scores.append(score)\n",
    "    return sum(scores) / len(scores) if scores else None\n",
    "\n",
    "def extract_score_from_result(result_text):\n",
    "    try:\n",
    "        # Assuming the score is at the end of the response text\n",
    "        score = int(result_text.strip().split()[-1])\n",
    "        return score\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "tweet = \"Exciting news! Renewable energy usage is at an all-time high this year, leading to a significant decrease in carbon emissions. #ClimateAction #GreenEnergy\"\n",
    "handlers = [\n",
    "    (ChatGPTHandler(api_key=os.getenv('OPENAI_API_KEY')), \"ChatGPT\"),\n",
    "    (GeminiHandler(api_key=os.getenv('GEMINI_API')), \"Gemini\"),\n",
    "    (LlamaHandler(api_key=os.getenv('LLAMA_API')), \"Llama\"),\n",
    "    (CohereHandler(api_key=os.getenv('COHERE_API_KEY')), \"Cohere\"),\n",
    "    (AI21Handler(api_key=os.getenv('AI21_API_KEY')), \"AI21\")\n",
    "]\n",
    "cross_validate_and_attack(tweet, handlers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "Metrics to evaluate the model. Your metric (custom), LLM metrics eg. Google SDK, and human evluation metric\n",
    "\n",
    "Need data.\n",
    "\n",
    "\n",
    "Sense of session - Automatic chain of thoughts in iterating social campaign.\n",
    "\n",
    "simulate a conversational or contextual continuity in the generation of tweets.\n",
    "This function iterates through prompts sequentially, where each subsequent generation is based on the output of the previous one, thereby maintaining a thematic and contextual thread throughout the session.\n",
    "\n",
    "Different models/gpts, 2 vs 4\n",
    "\n",
    "Finally:\n",
    "Run the code in the literatures (references) and modify them a bit and match our results and see if they align or not\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In previous note book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Fetch Tweet Text\n",
    "\n",
    "This function retrieves the text of a tweet by its ID using the Twitter API. It handles exceptions by printing an error message.\n",
    "\n",
    "\n",
    "Problem: Tweeter developer account need to be paid to use its recall API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tweet_text(tweet_id):\n",
    "    \"\"\"Fetch the text of a tweet given its ID.\"\"\"\n",
    "    try:\n",
    "        tweet = twitter_api.get_status(tweet_id, tweet_mode='extended')\n",
    "        return tweet.full_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tweet {tweet_id}: {e}\")\n",
    "        return None\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
